<!DOCTYPE html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-G9CWRQBRB0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-G9CWRQBRB0');
    </script>

    <meta charset="utf-8">
    <meta name="generator" content="pandoc">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    

    <!-- css -->
    <link rel="stylesheet" href="../../style/bootstrap-3.3.7-dist/css/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="../../style/my.css" type="text/css" />
    <link rel="stylesheet" href="../../style/projects.css" type="text/css" />

    <!-- Google Fonts -->
    <link href='https://fonts.googleapis.com/css?family=BioRhyme:200,300,400,700,800' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Raleway:400,300,700' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=VT323:400,300,700' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Baloo:400,300,700' rel='stylesheet' type='text/css'>
    <link href="https://fonts.googleapis.com/css?family=Averia+Serif+Libre" rel="stylesheet">

    <!-- Scripts -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.0/jquery.min.js"></script>
    <script src="/style/my.js"></script>
  </head>
  <body style="background-color: white;">
    <div class="container" style="background: white;">

      <h1 class="project-title"></h1>
      
      <hr>
          
      

      
      <hr>

      <h1 id="introduction">Introduction</h1>
<p>Realistic virtual worlds can serve as laboratories for carrying out
camera networks research. This unorthodox “Virtual Vision” paradigm
advocates developing visually and behaviorally realistic 3D environments
to serve the needs of computer vision. Our work on high-level
coordination and control in camera networks is a testament to the
suitability of virtual vision paradigm for camera networks research. The
prerequisite for carrying out virtual vision research is a virtual
vision simulator capable of generating synthetic imagery from simulated
real-life scenes. Here we present a distributed, customizable virtual
vision simulator capable of simulating pedestrian traffic in a variety
of 3D environments. Virtual cameras deployed in this synthetic
environment generate synthetic imagery—boasting realistic lighting
effects, shadows, etc.—using the state-of-the-art computer graphics
techniques. Our virtual vision simulator is realized as a collection of
modules that communicate with each other over the network. Consequently,
we can deploy our simulator over a network of computers, allowing us to
simulate much larger networks and much more complex scenes then is
otherwise possible.</p>
<h1 id="how-to-get-it-for-your-own-research">How to get it for your own
research?</h1>
<p>We have released the our virtual vision simulator to the community
under GNU General Public License V3.0 in order to support virtual vision
and camera networks research. Please feel free to download the code from
Github repository and use it for your own research. Please send us bug
fixes and improvements, so we may integrate them into the virtual vision
simulator. Notice that if you want to use parts of our code in a
commercial product they will need to comply with the <a
href="http://www.gnu.org/copyleft/gpl.html">GPLv3</a> license (all
derived products are required to be open source).</p>
<p>Thanks to (annevanrossum@gmail.com) for helping us with the above
wording.</p>
<p>Instructions about how to download, install and use our virtual
vision simulator are provided below.</p>
<h1 id="caveat">Caveat</h1>
<p>We purchased pedestrian models (textures and motion capture data)
from <a href="https://secure.axyz-design.com/">aXYZ Design</a>, which
hold the copyright to the pedestrian models. Licensing prevents us from
distributing these models. You will have to purchase these models for
our simulator to work properly.</p>
<p>If you are brave you may be able to use your own pedestrian models to
work with our simulator. The simulator simply needs a textured human
with animation data. If you plan to use your own pedestrian models, let
us know. Time permitting we might be able to work together to get things
rolling.</p>
<h1 id="citation">Citation</h1>
<p>Please cite the following publications when using our simulator for
research. Thank you!</p>
<p>“Smart Camera Networks in Virtual Reality,” F.Z. Qureshi, D.
Terzopoulos, Proceedings of the IEEE, 96(10), October, 2008, 1640—1656,
(Special Issue on “Smart Cameras”).</p>
<p>“Software laboratory for camera networks research,” W. Starzyk, F.Z.
Qureshi, IEEE Journal on Emerging and Selected Topics in Circuits and
Systems (special issue on “Computational and Smart Cameras), vol. 3,
iss. 2, pp. 284-293, 2013.</p>
<h1 id="publications">Publications</h1>
<p>This simulator is introduced in the following publications.</p>
<p>“Software laboratory for camera networks research,” W. Starzyk, F.Z.
Qureshi, IEEE Journal on Emerging and Selected Topics in Circuits and
Systems (special issue on “Computational and Smart Cameras), vol. 3,
iss. 2, pp. 284-293, 2013.</p>
<h1 id="projects-that-used-this-simulator">Projects that used this
Simulator</h1>
<p>We used the current simulator to carry out camera networks research,
which lead to the following two publications.</p>
<p>“Learning Proactive Control Strategies for PTZ Cameras,’’ F.Z.
Qureshi, W. Starzyk, Proc. 5th ACM/IEEE International Conference on
Distributed Smart Cameras (ICDSC 11), Ghent, Belgium, August, 2011,
1—6.</p>
<p>“Multitasking Smart Cameras for Intelligent Video Surveillance
Systems,’’ W. Starzyk, F.Z. Qureshi, Proc. 8th IEEE International
Conference on Advanced Video and Signal-Based Surveillance (AVSS 11),
Klagenfurt, Austria, August, 2011, 1—6.</p>
<h1 id="installation">Installation</h1>
<h2 id="linux">Linux</h2>
<p>The system is developed on Ubuntu 10.10 using packages from the
ubuntu repository. The following packages have to be installed:</p>
<ul>
<li>python2.6</li>
<li>python-numpy 1.3.0
http://sourceforge.net/projects/numpy/files/NumPy/1.3.0/</li>
<li>python-matplotlib 0.99.3
http://sourceforge.net/projects/matplotlib/files/matplotlib/matplotlib-0.99.3/</li>
<li>python-opencv 2.1.0
http://sourceforge.net/projects/opencvlibrary/files/opencv-unix/2.1/</li>
<li>python-wxgtk2.8 2.8.11
http://packages.ubuntu.com/search?keywords=python-wxgtk2.8</li>
<li>panda3d 1.7.2 from
http://www.panda3d.org/download.php?platform=ubuntu&amp;version=1.7.2&amp;sdk</li>
</ul>
<h2 id="windows">Windows</h2>
<ul>
<li>Install all of the libraries provided in the depenencies/windows
folder. Make sure you install Panda3D first.</li>
<li>Copy cv.lib and cv.pyd from the OPENCV_DIR-packages directory to the
PANDA3D_DIR-packages directory.
<ul>
<li>OPENCV_DIR is your opencv directory. By default this is C:</li>
<li>PANDA3D_DIR is your panda3D directory. By default this is
C:3D-1.7.2</li>
</ul></li>
<li>Make sure OPENCV_DIRis added to your Path</li>
</ul>
<h1 id="usage">Usage</h1>
<p>All of the provided applications are located in the src folder.</p>
<h2 id="simulator">Simulator</h2>
<p>Execute: <code>python 3D_Simulator.py [options]</code> Where options
are the options listed below. NOTE: specifying a configuration directory
is mandatory.</p>
<p>Options:</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">-</span>d directory    Set the directory where the config files are located</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">-</span>p port         Set the port the server should run on (default <span class="kw">is</span> <span class="dv">9099</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="op">-</span>a              Set the mode of the simulation controller to automatic (only used when server <span class="kw">not</span> needed)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="op">-</span>s              A Sync session <span class="kw">is</span> used to control the time</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="op">-</span>h              Print this <span class="bu">help</span> message <span class="kw">and</span> exit</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="op">--</span>debug         Show debug messages</span></code></pre></div>
<ul>
<li>left and right arrow keys switch between different cameras</li>
<li>escape exits the applications</li>
<li>i displays information about the simulator including ip address,
port and camera types</li>
</ul>
<h3 id="sync-client">Sync Client</h3>
<p>Execute:
<code>python Sync_Client.py [options] ip_address:port ip_address:port</code>
… Where ip_address:port is replaced with the ip address and port of all
the simulators</p>
<p>Options:</p>
<pre><code>--debug         Show debug messages</code></pre>
<h3 id="sample-client">Sample Client</h3>
<p>Execute: python sample_client.py [options]</p>
<p>Options:</p>
<pre><code>- p port        Set the port of the virtual world
- a ip_address  Set the ip address of the virtual world
- s             Save the images received from the server
- h             Print this help message and exit
--debug         Show debug messages</code></pre>
<h2 id="getting-started-guide">Getting Started Guide</h2>
<p>Please see the Getting Started Guide for step by step instructions on
how to use our Virtual Vision Simulator.</p>
<h3 id="configuring-a-scenario">Configuring a Scenario</h3>
<p>A scenario is made up of three config files which allow you to
configure the scene, the cameras and the pedestrians. These three files
must be called scene.xml, cameras.xml and pedestrians.xml and must be
placed in a single folder which can be specified using the
<code>-d</code> flag.</p>
<h4 id="scene.xml">scene.xml</h4>
<p>The <code>scene.xml</code> file is used to configure the 3D models
and lights that make up the scene. A sample is provided below.</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;scene&gt;
  &lt;models&gt;
    &lt;model path=&quot;../../media/scenes/office_floor/office_floor.egg&quot; scale=&quot;25&quot; pos=&quot;0 0 0&quot; hpr=&quot;0 0 0&quot; has_lighting=&#39;1&#39;/&gt;
    &lt;model path=&quot;../../media/scenes/office_floor/skybox.egg&quot; scale=&quot;25&quot; pos=&quot;0 0 50&quot; hpr=&quot;0 0 0&quot; has_lighting=&#39;0&#39;/&gt;
  &lt;/models&gt;
  &lt;lights&gt;
    &lt;light type=&quot;ambient&quot; color=&quot;0.8 0.8 0.8 1.0&quot;/&gt;
    &lt;light type=&quot;spotlight&quot; casts_shadow=&quot;1&quot; pos=&quot;-575 150 100&quot; fov=&quot;170&quot; exponent=&quot;1.5&quot;/&gt;
    &lt;light type=&quot;spotlight&quot; casts_shadow=&quot;1&quot; pos=&quot;-575 -150 100&quot; fov=&quot;170&quot; exponent=&quot;1.5&quot;/&gt;
  &lt;/lights&gt;
&lt;/scene&gt;</code></pre>
<h3 id="model">Model</h3>
<p>The following attributes must be set for all model tags: path: The
path to the 3D model relative to the scene.xml file scale: The scale of
the model hpr: The heading, pitch and roll of the model in degrees
(i.e. “180 0 0”) has_lighting: Set to 1 if the model is affected by
lighting. Our simulator supports three types of lights: ambient,
directional and spotlight. Ambient Light Mandatory Attributes type:
ambiant color: the color of the ambient light in the form of RGBA values
between 0 and 1 (i.e. “0.8 0.8 0.8 1.0”) Spotlight Mandatory Attributes
type: spotlight pos: The position of the light in x, y, z coordinates
(i.e. “300 150 100”) Optional Attributes fov: The field of view angle of
the light in degrees casts_shadow: 1 if the light casts shadows, 0
otherwise shadow_caster: The size of the shadow caster. Values should be
multiples of 2. (i.e. “2048 2048”) pitch: The pitch of the light in
degrees. The default is -90. near: The near plane of the light far: The
far plane of the light exponent: Sets the exponent that controls the
amount of light falloff from the center of the spotlight color: The
color of the light in the form of RGBA values between 0 and 1 (i.e. “0.5
0.5 0.5 1.0”) Directional Light Mandatory Attributes type: directional
pos: The position of the light in x, y, z coordinates hpr: The heading
pitch and roll of the model in degrees Optional Attributes casts_shadow:
1 if the light casts shadows, 0 otherwise shadow_caster: The size of the
shadow caster. Values should be multiples of 2. (i.e. “2048 2048”) near:
The near plane of the light far: The far plane of the light color: The
color of the light in the form of RGBA values between 0 and 1 (i.e. “0.5
0.5 0.5 1.0”) film_size: A rectangle that defines the region that will
be affected by the light. (i.e. “512 512”) cameras.xml The cameras.xml
file is used to configure the cameras. The sample provided below shows
all of the options that are currently available. Most of these options
should be self explanatory however, we would like to point out that the
id of each camera must be unique and the default_direction is the
direction the camera faces when the pan and tilt values are 0.
<?xml version="1.0" encoding="UTF-8"?> <cameras>
<camera type="rc_camera"> <color>0 255 0</color> <id>1</id>
<position>-575 90 -320</position> <up_vector>0 1 0</up_vector>
<near_plane>1</near_plane> <far_plane>100000</far_plane> <constraints>
<fov_limits>30 100</fov_limits>&gt; <pan_limits>-30 30</pan_limits>&gt;
<tilt_limits>-30 30</tilt_limits> </constraints> <default_direction>0 -2
4</default_direction> <default_fov>100</default_fov> <fov>100</fov>
</camera> </cameras> pedestrians.xml The pedestrians.xml file is used to
configure all of the pedestrians and their trajectories.
<?xml version='1.0' encoding='UTF-8'?> <pedestrians>
<pedestrian character='CMan0011' texture='CMan0011_3.png' pos='-780 0 -50' scale='25' hpr='0 0 0'>
<commands start_time='10'>walk walk l90 walk walk 180 walk walk
stand</commands> <pedestrian> </pedestrians> Pedestrian Attributes
character: One of CMan0011, CMan0012 or CMan0013 texture: The name of a
texture file (see media/characters/CHARACTER_NAME/textures) pos: The
starting position of the pedestrian in x, y, z coordinates. (i.e. “-350
0 -10”) scale: The scale of the model hpr: The heading, pitch and roll
of the model. (i.e. “180 0 0”) Commands The commands tag contains a list
of the commands that the pedestrian will execute. The available commands
are: walk does one walk cycle run does one run cycle stand stands
inplace 180 does an about turn l45 does a 45 degree turn to the left r45
does a 45 degree turn to the right r90 does a 90 degree turn to the
right l90 does a 90 degree turn to the left Additionally, you can use
the start_time attribute to specify when the pedestrian will start
executing its list of commands. Custom Client</p>


      <footer style="margin-top: 50px;">
  <div class="container footer">
    <div class="row">
      <hr>
      <div class="col-md-6 col-sm-12">
        <img src="/imgs/vclab-ontariotech-64.png" width="70%">
      </div>
      <div class="col-md-6 col-sm-12">
        &copy; Faisal Qureshi<br>
        Last updated <br>
        Site generated using &copy; Webify (Ver. 4.1)
      </div>
</footer>
      
    </div>

  </body>
</html>
