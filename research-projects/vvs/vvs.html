<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="generator" content="pandoc">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    

    <!-- css -->
    <link rel="stylesheet" href="../../style/bootstrap-3.3.7-dist/css/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="../../style/my.css" type="text/css" />
    <link rel="stylesheet" href="../../style/projects.css" type="text/css" />

    <!-- Google Fonts -->
    <link href='https://fonts.googleapis.com/css?family=BioRhyme:200,300,400,700,800' rel='stylesheet' type='text/css'> 
    <link href='https://fonts.googleapis.com/css?family=Raleway:400,300,700' rel='stylesheet' type='text/css'> 
    <link href='https://fonts.googleapis.com/css?family=VT323:400,300,700' rel='stylesheet' type='text/css'> 
    <link href='https://fonts.googleapis.com/css?family=Baloo:400,300,700' rel='stylesheet' type='text/css'> 
    <link href="https://fonts.googleapis.com/css?family=Averia+Serif+Libre" rel="stylesheet">
    
    <!-- Scripts -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.0/jquery.min.js"></script>
    <script src="../../style/my.js"></script>
  </head>
  <body style="background-color: white;">
    <div class="container" style="background: white;">

      <h1 class="project-title"></h1>
      
      
      <hr>
      <hr>
      
      <h1 id="introduction">Introduction</h1>
<p>Realistic virtual worlds can serve as laboratories for carrying out camera networks research. This unorthodox &quot;Virtual Vision&quot; paradigm advocates developing visually and behaviorally realistic 3D environments to serve the needs of computer vision. Our work on high-level coordination and control in camera networks is a testament to the suitability of virtual vision paradigm for camera networks research. The prerequisite for carrying out virtual vision research is a virtual vision simulator capable of generating synthetic imagery from simulated real-life scenes. Here we present a distributed, customizable virtual vision simulator capable of simulating pedestrian traffic in a variety of 3D environments. Virtual cameras deployed in this synthetic environment generate synthetic imagery—boasting realistic lighting effects, shadows, etc.—using the state-of-the-art computer graphics techniques. Our virtual vision simulator is realized as a collection of modules that communicate with each other over the network. Consequently, we can deploy our simulator over a network of computers, allowing us to simulate much larger networks and much more complex scenes then is otherwise possible.</p>
<h1 id="how-to-get-it-for-your-own-research">How to get it for your own research?</h1>
<p>We have released the our virtual vision simulator to the community under GNU General Public License V3.0 in order to support virtual vision and camera networks research. Please feel free to download the code from Github repository and use it for your own research. Please send us bug fixes and improvements, so we may integrate them into the virtual vision simulator. Notice that if you want to use parts of our code in a commercial product they will need to comply with the <a href="http://www.gnu.org/copyleft/gpl.html">GPLv3</a> license (all derived products are required to be open source).</p>
<p>Thanks to (annevanrossum@gmail.com) for helping us with the above wording.</p>
<p>Instructions about how to download, install and use our virtual vision simulator are provided below.</p>
<h1 id="caveat">Caveat</h1>
<p>We purchased pedestrian models (textures and motion capture data) from <a href="https://secure.axyz-design.com/">aXYZ Design</a>, which hold the copyright to the pedestrian models. Licensing prevents us from distributing these models. You will have to purchase these models for our simulator to work properly.</p>
<p>If you are brave you may be able to use your own pedestrian models to work with our simulator. The simulator simply needs a textured human with animation data. If you plan to use your own pedestrian models, let us know. Time permitting we might be able to work together to get things rolling.</p>
<h1 id="citation">Citation</h1>
<p>Please cite the following publications when using our simulator for research. Thank you!</p>
<p>&quot;Smart Camera Networks in Virtual Reality,&quot; F.Z. Qureshi, D. Terzopoulos, Proceedings of the IEEE, 96(10), October, 2008, 1640—1656, (Special Issue on &quot;Smart Cameras&quot;).</p>
<p>&quot;Software laboratory for camera networks research,&quot; W. Starzyk, F.Z. Qureshi, IEEE Journal on Emerging and Selected Topics in Circuits and Systems (special issue on &quot;Computational and Smart Cameras), vol. 3, iss. 2, pp. 284-293, 2013.</p>
<h1 id="publications">Publications</h1>
<p>This simulator is introduced in the following publications.</p>
<p>&quot;Software laboratory for camera networks research,&quot; W. Starzyk, F.Z. Qureshi, IEEE Journal on Emerging and Selected Topics in Circuits and Systems (special issue on &quot;Computational and Smart Cameras), vol. 3, iss. 2, pp. 284-293, 2013.</p>
<h1 id="projects-that-used-this-simulator">Projects that used this Simulator</h1>
<p>We used the current simulator to carry out camera networks research, which lead to the following two publications.</p>
<p>&quot;Learning Proactive Control Strategies for PTZ Cameras,'' F.Z. Qureshi, W. Starzyk, Proc. 5th ACM/IEEE International Conference on Distributed Smart Cameras (ICDSC 11), Ghent, Belgium, August, 2011, 1—6.</p>
<p>&quot;Multitasking Smart Cameras for Intelligent Video Surveillance Systems,'' W. Starzyk, F.Z. Qureshi, Proc. 8th IEEE International Conference on Advanced Video and Signal-Based Surveillance (AVSS 11), Klagenfurt, Austria, August, 2011, 1—6.</p>
<h1 id="installation">Installation</h1>
<h2 id="linux">Linux</h2>
<p>The system is developed on Ubuntu 10.10 using packages from the ubuntu repository. The following packages have to be installed:</p>
<ul>
<li>python2.6</li>
<li>python-numpy 1.3.0 http://sourceforge.net/projects/numpy/files/NumPy/1.3.0/</li>
<li>python-matplotlib 0.99.3 http://sourceforge.net/projects/matplotlib/files/matplotlib/matplotlib-0.99.3/</li>
<li>python-opencv 2.1.0 http://sourceforge.net/projects/opencvlibrary/files/opencv-unix/2.1/</li>
<li>python-wxgtk2.8 2.8.11 http://packages.ubuntu.com/search?keywords=python-wxgtk2.8</li>
<li>panda3d 1.7.2 from http://www.panda3d.org/download.php?platform=ubuntu&amp;version=1.7.2&amp;sdk</li>
</ul>
<h2 id="windows">Windows</h2>
<ul>
<li>Install all of the libraries provided in the depenencies/windows folder. Make sure you install Panda3D first.</li>
<li>Copy cv.lib and cv.pyd from the OPENCV_DIR2.6-packages directory to the PANDA3D_DIR-packages directory.
<ul>
<li>OPENCV_DIR is your opencv directory. By default this is C:2.1</li>
<li>PANDA3D_DIR is your panda3D directory. By default this is C:3D-1.7.2</li>
</ul></li>
<li>Make sure OPENCV_DIRis added to your Path</li>
</ul>
<h1 id="usage">Usage</h1>
<p>All of the provided applications are located in the src folder.</p>
<h2 id="simulator">Simulator</h2>
<p>Execute: <code>python 3D_Simulator.py [options]</code> Where options are the options listed below. NOTE: specifying a configuration directory is mandatory.</p>
<p>Options:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="op">-</span>d directory    Set the directory where the config files are located
<span class="op">-</span>p port         Set the port the server should run on (default <span class="kw">is</span> <span class="dv">9099</span>)
<span class="op">-</span>a              Set the mode of the simulation controller to automatic (only used when server <span class="kw">not</span> needed)
<span class="op">-</span>s              A Sync session <span class="kw">is</span> used to control the time
<span class="op">-</span>h              Print this <span class="bu">help</span> message <span class="kw">and</span> exit
<span class="op">--</span>debug         Show debug messages</code></pre></div>
<ul>
<li>left and right arrow keys switch between different cameras</li>
<li>escape exits the applications</li>
<li>i displays information about the simulator including ip address, port and camera types</li>
</ul>
<h3 id="sync-client">Sync Client</h3>
<p>Execute: <code>python Sync_Client.py [options] ip_address:port ip_address:port</code> ... Where ip_address:port is replaced with the ip address and port of all the simulators</p>
<p>Options:</p>
<pre><code>--debug         Show debug messages</code></pre>
<h3 id="sample-client">Sample Client</h3>
<p>Execute: python sample_client.py [options]</p>
<p>Options:</p>
<pre><code>- p port        Set the port of the virtual world
- a ip_address  Set the ip address of the virtual world
- s             Save the images received from the server
- h             Print this help message and exit
--debug         Show debug messages</code></pre>
<h2 id="getting-started-guide">Getting Started Guide</h2>
<p>Please see the Getting Started Guide for step by step instructions on how to use our Virtual Vision Simulator.</p>
<h3 id="configuring-a-scenario">Configuring a Scenario</h3>
<p>A scenario is made up of three config files which allow you to configure the scene, the cameras and the pedestrians. These three files must be called scene.xml, cameras.xml and pedestrians.xml and must be placed in a single folder which can be specified using the <code>-d</code> flag.</p>
<h4 id="scene.xml">scene.xml</h4>
<p>The <code>scene.xml</code> file is used to configure the 3D models and lights that make up the scene. A sample is provided below.</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;scene&gt;
  &lt;models&gt;
    &lt;model path=&quot;../../media/scenes/office_floor/office_floor.egg&quot; scale=&quot;25&quot; pos=&quot;0 0 0&quot; hpr=&quot;0 0 0&quot; has_lighting=&#39;1&#39;/&gt;
    &lt;model path=&quot;../../media/scenes/office_floor/skybox.egg&quot; scale=&quot;25&quot; pos=&quot;0 0 50&quot; hpr=&quot;0 0 0&quot; has_lighting=&#39;0&#39;/&gt;
  &lt;/models&gt;
  &lt;lights&gt;
    &lt;light type=&quot;ambient&quot; color=&quot;0.8 0.8 0.8 1.0&quot;/&gt;
    &lt;light type=&quot;spotlight&quot; casts_shadow=&quot;1&quot; pos=&quot;-575 150 100&quot; fov=&quot;170&quot; exponent=&quot;1.5&quot;/&gt;
    &lt;light type=&quot;spotlight&quot; casts_shadow=&quot;1&quot; pos=&quot;-575 -150 100&quot; fov=&quot;170&quot; exponent=&quot;1.5&quot;/&gt;
  &lt;/lights&gt;
&lt;/scene&gt;</code></pre>
<h3 id="model">Model</h3>
The following attributes must be set for all model tags: path: The path to the 3D model relative to the scene.xml file scale: The scale of the model hpr: The heading, pitch and roll of the model in degrees (i.e. &quot;180 0 0&quot;) has_lighting: Set to 1 if the model is affected by lighting. Our simulator supports three types of lights: ambient, directional and spotlight. Ambient Light Mandatory Attributes type: ambiant color: the color of the ambient light in the form of RGBA values between 0 and 1 (i.e. &quot;0.8 0.8 0.8 1.0&quot;) Spotlight Mandatory Attributes type: spotlight pos: The position of the light in x, y, z coordinates (i.e. &quot;300 150 100&quot;) Optional Attributes fov: The field of view angle of the light in degrees casts_shadow: 1 if the light casts shadows, 0 otherwise shadow_caster: The size of the shadow caster. Values should be multiples of 2. (i.e. &quot;2048 2048&quot;) pitch: The pitch of the light in degrees. The default is -90. near: The near plane of the light far: The far plane of the light exponent: Sets the exponent that controls the amount of light falloff from the center of the spotlight color: The color of the light in the form of RGBA values between 0 and 1 (i.e. &quot;0.5 0.5 0.5 1.0&quot;) Directional Light Mandatory Attributes type: directional pos: The position of the light in x, y, z coordinates hpr: The heading pitch and roll of the model in degrees Optional Attributes casts_shadow: 1 if the light casts shadows, 0 otherwise shadow_caster: The size of the shadow caster. Values should be multiples of 2. (i.e. &quot;2048 2048&quot;) near: The near plane of the light far: The far plane of the light color: The color of the light in the form of RGBA values between 0 and 1 (i.e. &quot;0.5 0.5 0.5 1.0&quot;) film_size: A rectangle that defines the region that will be affected by the light. (i.e. &quot;512 512&quot;) cameras.xml The cameras.xml file is used to configure the cameras. The sample provided below shows all of the options that are currently available. Most of these options should be self explanatory however, we would like to point out that the id of each camera must be unique and the default_direction is the direction the camera faces when the pan and tilt values are 0.
<?xml version="1.0" encoding="UTF-8"?>
<cameras> <camera type="rc_camera"> <color>0 255 0</color> <id>1</id> <position>-575 90 -320</position> <up_vector>0 1 0</up_vector> <near_plane>1</near_plane> <far_plane>100000</far_plane> <constraints> <fov_limits>30 100</fov_limits>&gt; <pan_limits>-30 30</pan_limits>&gt; <tilt_limits>-30 30</tilt_limits> </constraints> <default_direction>0 -2 4</default_direction> <default_fov>100</default_fov> <fov>100</fov> </camera> </cameras> pedestrians.xml The pedestrians.xml file is used to configure all of the pedestrians and their trajectories.
<?xml version='1.0' encoding='UTF-8'?>
<p><pedestrians> <pedestrian character='CMan0011' texture='CMan0011_3.png' pos='-780 0 -50' scale='25' hpr='0 0 0'> <commands start_time='10'>walk walk l90 walk walk 180 walk walk stand</commands> <pedestrian> </pedestrians> Pedestrian Attributes character: One of CMan0011, CMan0012 or CMan0013 texture: The name of a texture file (see media/characters/CHARACTER_NAME/textures) pos: The starting position of the pedestrian in x, y, z coordinates. (i.e. &quot;-350 0 -10&quot;) scale: The scale of the model hpr: The heading, pitch and roll of the model. (i.e. &quot;180 0 0&quot;) Commands The commands tag contains a list of the commands that the pedestrian will execute. The available commands are: walk does one walk cycle run does one run cycle stand stands inplace 180 does an about turn l45 does a 45 degree turn to the left r45 does a 45 degree turn to the right r90 does a 90 degree turn to the right l90 does a 90 degree turn to the left Additionally, you can use the start_time attribute to specify when the pedestrian will start executing its list of commands. Custom Client</p>

    </div>

  </body>
</html>
